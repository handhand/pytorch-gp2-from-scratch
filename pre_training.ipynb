{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. 准备一个小的数据来预训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('the-verdict.txt', <http.client.HTTPMessage at 0x29ce4f503d0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
    "       \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
    "       \"the-verdict.txt\")\n",
    "file_path = \"the-verdict.txt\"\n",
    "urllib.request.urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 定义hyper parameters\n",
    "加载数据时也要配合里边的参数，所以参数设置放在前边"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 准备数据loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MyGPT2.pretrain_data_utils import create_data_loader\n",
    "\n",
    "# read the text and split\n",
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text_data = f.read()\n",
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "# get the dataloader from the text\n",
    "train_loader = create_data_loader(\n",
    "    train_data,\n",
    "    batch_size=1,\n",
    "    sample_len=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader = create_data_loader(\n",
    "    train_data,\n",
    "    batch_size=1,\n",
    "    sample_len=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (layer_norm1): LayerNorm()\n",
       "      (mha): MultiheadAttention(\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (layer_norm1): LayerNorm()\n",
       "      (mha): MultiheadAttention(\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (layer_norm1): LayerNorm()\n",
       "      (mha): MultiheadAttention(\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (layer_norm1): LayerNorm()\n",
       "      (mha): MultiheadAttention(\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (layer_norm1): LayerNorm()\n",
       "      (mha): MultiheadAttention(\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (layer_norm1): LayerNorm()\n",
       "      (mha): MultiheadAttention(\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (layer_norm1): LayerNorm()\n",
       "      (mha): MultiheadAttention(\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (layer_norm1): LayerNorm()\n",
       "      (mha): MultiheadAttention(\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (layer_norm1): LayerNorm()\n",
       "      (mha): MultiheadAttention(\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (layer_norm1): LayerNorm()\n",
       "      (mha): MultiheadAttention(\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (layer_norm1): LayerNorm()\n",
       "      (mha): MultiheadAttention(\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (layer_norm1): LayerNorm()\n",
       "      (mha): MultiheadAttention(\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from MyGPT2.gpt2_model import GPT2Model\n",
    "\n",
    "model = GPT2Model(GPT_CONFIG_124M)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 8.327, Val loss 8.427\n",
      "Ep 1 (Step 000005): Train loss 7.795, Val loss 7.531\n",
      "Ep 1 (Step 000010): Train loss 7.245, Val loss 7.382\n",
      "Ep 1 (Step 000015): Train loss 7.490, Val loss 7.123\n",
      "Ep 2 (Step 000020): Train loss 6.892, Val loss 6.680\n",
      "Ep 2 (Step 000025): Train loss 5.940, Val loss 6.047\n",
      "Ep 2 (Step 000030): Train loss 5.622, Val loss 5.462\n",
      "Ep 2 (Step 000035): Train loss 4.674, Val loss 4.895\n",
      "Ep 3 (Step 000040): Train loss 4.938, Val loss 5.141\n",
      "Ep 3 (Step 000045): Train loss 4.261, Val loss 4.342\n",
      "Ep 3 (Step 000050): Train loss 3.907, Val loss 4.014\n",
      "Ep 4 (Step 000055): Train loss 3.055, Val loss 3.419\n",
      "Ep 4 (Step 000060): Train loss 3.249, Val loss 3.297\n",
      "Ep 4 (Step 000065): Train loss 2.822, Val loss 2.612\n",
      "Ep 4 (Step 000070): Train loss 2.664, Val loss 2.866\n",
      "Ep 5 (Step 000075): Train loss 2.160, Val loss 1.937\n",
      "Ep 5 (Step 000080): Train loss 1.375, Val loss 1.857\n",
      "Ep 5 (Step 000085): Train loss 1.265, Val loss 1.559\n",
      "Ep 6 (Step 000090): Train loss 0.897, Val loss 1.040\n",
      "Ep 6 (Step 000095): Train loss 0.890, Val loss 0.761\n",
      "Ep 6 (Step 000100): Train loss 0.792, Val loss 0.752\n",
      "Ep 6 (Step 000105): Train loss 0.705, Val loss 0.797\n",
      "Ep 7 (Step 000110): Train loss 0.483, Val loss 0.566\n",
      "Ep 7 (Step 000115): Train loss 0.366, Val loss 0.351\n",
      "Ep 7 (Step 000120): Train loss 0.263, Val loss 0.347\n",
      "Ep 7 (Step 000125): Train loss 0.327, Val loss 0.240\n",
      "Ep 8 (Step 000130): Train loss 0.212, Val loss 0.237\n",
      "Ep 8 (Step 000135): Train loss 0.236, Val loss 0.346\n",
      "Ep 8 (Step 000140): Train loss 0.284, Val loss 0.260\n",
      "Ep 9 (Step 000145): Train loss 0.210, Val loss 0.234\n",
      "Ep 9 (Step 000150): Train loss 0.220, Val loss 0.270\n",
      "Ep 9 (Step 000155): Train loss 0.234, Val loss 0.120\n",
      "Ep 9 (Step 000160): Train loss 0.129, Val loss 0.123\n",
      "Ep 10 (Step 000165): Train loss 0.124, Val loss 0.141\n",
      "Ep 10 (Step 000170): Train loss 0.173, Val loss 0.117\n",
      "Ep 10 (Step 000175): Train loss 0.074, Val loss 0.109\n"
     ]
    }
   ],
   "source": [
    "from MyGPT2.train_utils import train_model_simple\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr = 0.0004, weight_decay=0.1\n",
    ")\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=\"won't use for now...\",\n",
    "    tokenizer=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 生成字符测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text: Jack is a very surface to work on--forming, as it were, so inevitably the background of her own picture--had lent herself in an\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from MyGPT2.text_utils import text_to_ids\n",
    "from MyGPT2.text_utils import generate_text_simple\n",
    "from MyGPT2.text_utils import ids_to_text\n",
    "\n",
    "start_context = \"Jack is a very\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "output_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx = text_to_ids(start_context, tokenizer=tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\", ids_to_text(output_ids, tokenizer=tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
