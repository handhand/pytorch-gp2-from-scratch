{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 18])\n",
      "tensor([[[-1.5060e-01,  1.5275e-01, -9.1317e-03, -2.3914e-02, -2.1646e-01,\n",
      "          -8.5258e-02, -5.3132e-02, -2.7035e-01,  3.5042e-01, -6.4252e-01,\n",
      "           1.5185e-01, -7.4330e-01, -9.8712e-02, -2.1476e-01,  3.4890e-01,\n",
      "           4.1000e-01,  3.8845e-01, -5.2940e-01],\n",
      "         [-1.0497e-01,  1.1653e-01, -2.9727e-02, -6.9519e-02, -2.5803e-01,\n",
      "          -1.2932e-02,  1.3819e-02, -2.9035e-01,  3.4350e-01, -6.8724e-01,\n",
      "           8.5218e-02, -7.2530e-01, -8.1888e-02, -2.0641e-01,  3.1913e-01,\n",
      "           3.6297e-01,  3.9304e-01, -4.8028e-01],\n",
      "         [-1.2476e-01,  9.8586e-02, -4.8008e-02,  1.2542e-02, -2.0347e-01,\n",
      "          -1.0444e-02,  1.7996e-02, -3.0392e-01,  2.8951e-01, -6.3832e-01,\n",
      "           1.1868e-01, -6.8527e-01, -7.3992e-02, -2.6274e-01,  3.0713e-01,\n",
      "           4.0264e-01,  3.6505e-01, -4.6554e-01],\n",
      "         [-1.9230e-01,  1.0514e-01, -3.3738e-02, -2.2307e-02, -1.7486e-01,\n",
      "          -1.4086e-02, -3.9202e-03, -2.9495e-01,  2.8554e-01, -6.9103e-01,\n",
      "           1.4182e-01, -7.3741e-01, -8.2812e-02, -2.6453e-01,  3.6145e-01,\n",
      "           4.6684e-01,  3.7528e-01, -5.0319e-01]],\n",
      "\n",
      "        [[-2.3394e-01,  1.1129e-02, -7.3705e-02, -2.1538e-01, -2.7296e-01,\n",
      "           1.3624e-01, -1.1010e-01, -2.9150e-01,  5.1938e-02, -7.1433e-01,\n",
      "           2.8655e-02, -8.6139e-01, -2.3974e-01, -2.9704e-01,  5.1143e-01,\n",
      "           3.3871e-01,  2.1613e-01, -3.4438e-01],\n",
      "         [-2.5452e-01,  1.6510e-01, -2.3961e-02, -1.7280e-01, -1.3673e-01,\n",
      "           6.9902e-02, -7.7483e-02, -2.3233e-01,  2.1927e-01, -6.2467e-01,\n",
      "           7.6333e-02, -8.2118e-01, -2.2021e-01, -3.8884e-01,  4.2969e-01,\n",
      "           3.8604e-01,  2.7429e-01, -5.1104e-01],\n",
      "         [-2.2113e-01,  2.0291e-02, -1.8726e-02,  1.0455e-03, -1.7428e-01,\n",
      "           4.7105e-02, -4.4568e-02, -1.8143e-01,  2.0411e-01, -5.1553e-01,\n",
      "           9.5496e-02, -6.8725e-01, -6.6443e-02, -1.9904e-01,  3.2971e-01,\n",
      "           3.2747e-01,  3.2309e-01, -4.0837e-01],\n",
      "         [-2.2653e-01,  8.8028e-02,  5.6535e-04, -1.4138e-01, -1.6797e-01,\n",
      "           7.4473e-02, -5.1305e-02, -2.2183e-01,  2.6578e-01, -6.0058e-01,\n",
      "           1.0943e-01, -7.9356e-01, -1.5851e-01, -2.5377e-01,  3.8393e-01,\n",
      "           3.5277e-01,  3.2705e-01, -4.5550e-01]]], grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1314"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from MyGPT2.multihead_attention import MultiheadAttention\n",
    "import torch\n",
    "\n",
    "# test code\n",
    "att = MultiheadAttention(input_dim = 18, heads = 3, head_dim = 6, drop_rate = 0.1, qkv_bias = False, context_length = 100)\n",
    "inp = torch.rand(2, 4, 18)\n",
    "print(att(inp).shape) # expected [2, 4, 18]\n",
    "print(att(inp))\n",
    "pytorch_total_params = sum(p.numel() for p in att.parameters() if p.requires_grad)\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "6\n",
      "3\n",
      "torch.Size([2, 3, 18])\n"
     ]
    }
   ],
   "source": [
    "from MyGPT2.transformer_block import TransformerBlock\n",
    "import torch\n",
    "\n",
    "cfg = {\n",
    "    \"emb_dim\": 18,\n",
    "    \"n_heads\": 6,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False,\n",
    "    \"context_length\": 12\n",
    "}\n",
    "\n",
    "transformerBlock = TransformerBlock(cfg)\n",
    "input = torch.rand(2, 3, 18)\n",
    "output = transformerBlock(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.4859, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from MyGPT2.train_utils import calc_loss_batch\n",
    "from MyGPT2.gpt2_model import GPT2Model\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Note 1: input and target shape are the same!\n",
    "# Note 2: torch.tensor must use dypte=torch.long\n",
    "test_batch = torch.tensor([[1,2,3],[1,2,3]], dtype=torch.long)\n",
    "test_target = torch.tensor([[1,2,3],[1,2,3]], dtype=torch.long)\n",
    "cfg = {\n",
    "    \"vocab_size\": 50,     # Vocabulary size\n",
    "    \"context_length\": 10,  # Context length\n",
    "    \"emb_dim\": 10,          # Embedding dimension\n",
    "    \"n_heads\": 5,           # Number of attention heads\n",
    "    \"n_layers\": 12,          # Number of layers\n",
    "    \"drop_rate\": 0.1,        # Dropout rate\n",
    "    \"qkv_bias\": False        # Query-Key-Value bias\n",
    "}\n",
    "model = GPT2Model(cfg)\n",
    "result = calc_loss_batch(test_batch, test_target, model, device)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
