{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download_and_load_gpt2 是作者准备的下载gpt2官方weight的脚本（需要tensorflow支持）\n",
    "\n",
    "方法返回模型的setting，和一个字典，key是层，value是numpy保存的各层参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=\"124M\", models_dir=\"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "官方的GPT2配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\n",
    "        \"vocab_size\": 50257,\n",
    "        \"context_length\": 1024,\n",
    "        \"emb_dim\": 768,\n",
    "        \"n_heads\": 12,\n",
    "        \"n_layers\": 12,\n",
    "        \"drop_rate\": 0.1,\n",
    "        \"qkv_bias\": True\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def assign(left, right):\n",
    "    '''\n",
    "    保证right的shape和left相等，然后将right作为pytorch parameter返回\n",
    "    '''\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n",
    "                          \"Right: {right.shape}\"\n",
    "        )\n",
    "    return torch.nn.Parameter(torch.tensor(right))\n",
    "\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    '''\n",
    "    gpt pytorch模型\n",
    "    params 从官方下载的参数，是一个字典，key是不同的层，value是层的参数\n",
    "    '''\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params[\"wpe\"])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params[\"wte\"])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].mha.q_proj.weight = assign(gpt.trf_blocks[b].mha.q_proj.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].mha.k_proj.weight = assign(gpt.trf_blocks[b].mha.k_proj.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].mha.v_proj.weight = assign(gpt.trf_blocks[b].mha.v_proj.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].mha.q_proj.bias = assign(gpt.trf_blocks[b].mha.q_proj.bias, q_b)\n",
    "        gpt.trf_blocks[b].mha.k_proj.bias = assign(gpt.trf_blocks[b].mha.k_proj.bias, k_b)\n",
    "        gpt.trf_blocks[b].mha.v_proj.bias = assign(gpt.trf_blocks[b].mha.v_proj.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].mha.proj.weight = assign(\n",
    "            gpt.trf_blocks[b].mha.proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].mha.proj.bias = assign(\n",
    "            gpt.trf_blocks[b].mha.proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "         \n",
    "        # 下边feed forward layers取0和2的是因为 feedforward是 sequential，\n",
    "        # 第0，2是Linear，第1层是Gelu\n",
    "        gpt.trf_blocks[b].feed_forward.layer[0].weight = assign(\n",
    "            gpt.trf_blocks[b].feed_forward.layer[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].feed_forward.layer[0].bias = assign(\n",
    "            gpt.trf_blocks[b].feed_forward.layer[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].feed_forward.layer[2].weight = assign(\n",
    "            gpt.trf_blocks[b].feed_forward.layer[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].feed_forward.layer[2].bias = assign(\n",
    "            gpt.trf_blocks[b].feed_forward.layer[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "        \n",
    "        gpt.trf_blocks[b].layer_norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].layer_norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].layer_norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].layer_norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].layer_norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].layer_norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].layer_norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].layer_norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "    \n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MyGPT2.gpt2_model import GPT2Model\n",
    "\n",
    "model = GPT2Model(model_configs[\"gpt2-small (124M)\"])\n",
    "load_weights_into_gpt(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text: Every effort moves you to the next step.\n",
      "\n",
      "The first step is to get your life back on track.\n",
      "\n",
      "The second step is to get your life back on track.\n",
      "\n",
      "The third step is to get your life back on track.\n",
      "\n",
      "The\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from MyGPT2.text_utils import text_to_ids\n",
    "from MyGPT2.text_utils import generate_text_simple\n",
    "from MyGPT2.text_utils import ids_to_text\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "output_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx = text_to_ids(start_context, tokenizer=tokenizer),\n",
    "    max_new_tokens=50,\n",
    "    context_size=model_configs[\"gpt2-small (124M)\"][\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\", ids_to_text(output_ids, tokenizer=tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
